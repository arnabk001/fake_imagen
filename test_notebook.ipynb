{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# helper function to show masks\n",
    "def show_mask(mask, ax, random_color=False, borders = True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "        # Try to smooth contours\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))    \n",
    "\n",
    "def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # boxes\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# building predictor\n",
    "sam2_checkpoint = \"segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    "\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def yolo_keypoints(image_path):\n",
    "    # Load a model\n",
    "    model = YOLO(\"yolov8n.pt\")  # pretrained YOLOv8n model\n",
    "\n",
    "    results = model(image_path,\n",
    "                    conf = 0.5)  # return a list of Results objects\n",
    "    # print(\"results_list_len: =\", len(results))\n",
    "    if len(results) == 1:\n",
    "        # Process results list - single image infrence\n",
    "        xyxy = results[0].boxes.xyxy  # Boxes object for bounding box outputs\n",
    "        xyxy = xyxy.cpu().detach().numpy()\n",
    "    elif len(results) > 1:\n",
    "        xyxy = []\n",
    "        # Process results list - multi-image infrence\n",
    "        for result in results:\n",
    "            xyxy.append(result.boxes.xyxy)  # Boxes object for bounding box outputs\n",
    "\n",
    "    return xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ubuntu/arnab/sd_inpainting_datagen/test1.webp: 384x640 8 persons, 1 dog, 1 handbag, 1 chair, 16.2ms\n",
      "Speed: 1.7ms preprocess, 16.2ms inference, 21.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "# loading the image\n",
    "image_path = \"test1.webp\"\n",
    "image = Image.open(image_path)\n",
    "image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "\n",
    "predictor.set_image(image)\n",
    "\n",
    "\n",
    "# define input coordinates in xyxy format - get coordinates from yolov2\n",
    "# will be coming from yolov8\n",
    "input_box = yolo_keypoints(image_path)\n",
    "\n",
    "# take top 5 keypoints\n",
    "top_k = 5\n",
    "input_box = input_box[:top_k]\n",
    "print(input_box.shape)\n",
    "\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_box[None,:],\n",
    "    multimask_output=False,\n",
    ")\n",
    "\n",
    "save_masks(masks, dir='./masks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_masks(masks, prefix=\"mask\", dir=\"masks\"):\n",
    "    \"\"\"\n",
    "    Save the masks as PNG images in the specified directory.\n",
    "    \n",
    "    Args:\n",
    "    - masks (numpy.ndarray): The masks array with shape [N, 1, h, w].\n",
    "    - prefix (str): The prefix for the saved image filenames.\n",
    "    - dir (str): The directory where the masks will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    # Check the shape of the masks array\n",
    "    N, _, h, w = masks.shape\n",
    "\n",
    "    for i in range(N):\n",
    "        mask = masks[i, 0]  # Get the mask for the ith item, shape [h, w]\n",
    "        \n",
    "        # Convert the numpy array to a PIL Image\n",
    "        pil_image = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "        \n",
    "        # Optionally, convert to 'L' mode for grayscale if needed\n",
    "        pil_image = pil_image.convert(\"L\")\n",
    "        \n",
    "        # Construct the file path\n",
    "        file_path = os.path.join(dir, f\"{prefix}_{i}.png\")\n",
    "        \n",
    "        # Save the image\n",
    "        pil_image.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.amin(masks[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts():\n",
    "    #TODO prompts from gpt\n",
    "    prompt = \"a lady with long hair\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:39<00:00,  6.50s/it]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import torch\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(951, 535)\n",
      "(951, 535)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:07<00:00,  6.56it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt = get_prompts()\n",
    "\n",
    "#image and mask_image should be PIL images.\n",
    "#The mask structure is white for inpainting and black for keeping as is\n",
    "input_image = Image.open('test1.webp')\n",
    "print(input_image.size)\n",
    "mask_image = Image.open('masks/mask_2.png')\n",
    "print(mask_image.size)\n",
    "\n",
    "image = pipe(prompt=prompt, image=input_image, mask_image=mask_image).images[0]\n",
    "image.save(\"./test1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdinpaint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
